# ========================================
# LLM FIREWALL - ENVIRONMENT CONFIGURATION
# ========================================

# ----------------------------------------
# Gateway Service Configuration
# ----------------------------------------
GATEWAY_PORT=3000
GATEWAY_HOST=0.0.0.0
NODE_ENV=development

# Logging
LOG_LEVEL=info
LOG_PRETTY=true

# ----------------------------------------
# Analyzer Service Configuration
# ----------------------------------------
ANALYZER_HOST=analyzer-service
ANALYZER_PORT=50051
GRPC_TIMEOUT_MS=5000
GRPC_MAX_RETRIES=3

# ----------------------------------------
# Redis Configuration (Rate Limiting)
# ----------------------------------------
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0
REDIS_KEY_PREFIX=llm_firewall:

# Rate Limiting Configuration
RATE_LIMIT_GLOBAL=10000
RATE_LIMIT_GLOBAL_WINDOW=3600
RATE_LIMIT_PER_IP=100
RATE_LIMIT_PER_IP_WINDOW=3600
RATE_LIMIT_PER_API_KEY=1000
RATE_LIMIT_PER_API_KEY_WINDOW=3600

# ----------------------------------------
# PostgreSQL Configuration (Audit Logs)
# ----------------------------------------
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=firewall_audit
POSTGRES_USER=firewall
POSTGRES_PASSWORD=changeme_secure_password

# Audit Log Configuration
AUDIT_LOG_RETENTION_DAYS=90
AUDIT_LOG_ASYNC=true

# ----------------------------------------
# Security Configuration
# ----------------------------------------
# PII Detection
PII_CONFIDENCE_THRESHOLD=0.7
PII_ENTITIES=EMAIL,PHONE_NUMBER,CREDIT_CARD,SSN,IP_ADDRESS,PERSON,LOCATION

# Prompt Injection Detection
PROMPT_INJECTION_ENABLED=true
PROMPT_INJECTION_SENSITIVITY=moderate
SPECIAL_CHAR_THRESHOLD=0.1

# Content Safety
MAX_CONTENT_LENGTH=10240
MIN_CONTENT_LENGTH=1

# ----------------------------------------
# LLM Provider Configuration
# ----------------------------------------
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_API_BASE=https://api.openai.com/v1
OPENAI_MODEL=gpt-4
OPENAI_TIMEOUT_MS=30000

ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here
ANTHROPIC_API_BASE=https://api.anthropic.com/v1
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# ----------------------------------------
# Observability Configuration
# ----------------------------------------
# OpenTelemetry
OTEL_ENABLED=true
OTEL_SERVICE_NAME=llm-firewall
OTEL_SERVICE_VERSION=1.0.0

# Prometheus
PROMETHEUS_PORT=9090
PROMETHEUS_METRICS_ENDPOINT=/metrics

# Jaeger
JAEGER_ENABLED=false
JAEGER_AGENT_HOST=jaeger
JAEGER_AGENT_PORT=6831

# ----------------------------------------
# Feature Flags
# ----------------------------------------
FEATURE_PII_DETECTION=true
FEATURE_PROMPT_INJECTION=true
FEATURE_RATE_LIMITING=true
FEATURE_AUDIT_LOGGING=true
FEATURE_ANONYMIZATION=false
FEATURE_ML_JAILBREAK=false

# ----------------------------------------
# Security Headers
# ----------------------------------------
HELMET_ENABLED=true
CORS_ENABLED=true
CORS_ORIGIN=*
CORS_METHODS=GET,POST,OPTIONS

# ----------------------------------------
# Docker & Development
# ----------------------------------------
# Set to 'production' when deploying
ENVIRONMENT=development

# Health Check Configuration
HEALTH_CHECK_INTERVAL_MS=10000
READINESS_CHECK_TIMEOUT_MS=2000

# Graceful Shutdown
SHUTDOWN_TIMEOUT_MS=10000

# ----------------------------------------
# Advanced Configuration
# ----------------------------------------
# gRPC Configuration
GRPC_MAX_MESSAGE_SIZE=4194304
GRPC_MAX_WORKERS=10
GRPC_KEEPALIVE_TIME_MS=10000

# Connection Pooling
DB_POOL_MIN=2
DB_POOL_MAX=10
REDIS_POOL_MIN=5
REDIS_POOL_MAX=20

# ----------------------------------------
# Monitoring & Alerts (Optional)
# ----------------------------------------
SLACK_WEBHOOK_URL=
PAGERDUTY_API_KEY=
ALERT_ERROR_THRESHOLD=100
ALERT_LATENCY_P99_MS=100
